# -*- coding: utf-8 -*-
"""
Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1qUyDoo9MOi9QIIXFtrEtZXKxZLOwWQ4Z

# Integrantes:
# - Martínez Chávez Cristofer Benjamín
# - Quispe Yauri Rosario Lizeth
# - Rodríguez Galindo Rogelio Armando

"""

import pandas as pd #df is your dataframe
# Carga los datos de los archivos CSV
# Primero calificaciones de matemáticas y luego de portugués

df_mat = pd.read_csv('data/student-mat.csv', sep=';')
df_por = pd.read_csv('data/student-por.csv', sep=';')

# Primero analizar matemáticas
print("===================================")
print("=Calificaciones de Matemáticas=")
print("===================================")
print(df_mat.shape)
print(df_mat.head())
print(df_mat.info())
print(df_mat.describe())

# Primero analizar portugues
print("===================================")
print("=Calificaciones de Portugués=")
print("===================================")
print(df_por.shape)
print(df_por.head())
print(df_por.info())
print(df_por.describe())

# Los DataFrames son iguales entonces los podemos unir
df = pd.concat([df_mat, df_por], axis=0, ignore_index=True)
# Ahora analizamos el DataFrame combinado
print("===================================")
print("=Calificaciones combinadas =")
print("===================================")
print(df.shape)
print(df.head())
print(df.info())
print(df.describe())

# Guardamos el DataFrame combinado en un nuevo archivo CSV
df.to_csv('data/calificaciones_combinadas.csv', index=False)

# Ahora podemos realizar un análisis más detallado
#Buscar valores nulos
print("===================================")
print("=Valores nulos en el DataFrame combinado=")
print("===================================")
print(df.isnull().sum())

# Análisis de valores duplicados
print("===================================")
print("=Valores duplicados en el DataFrame combinado=")
print("===================================")
print(df.duplicated().sum())

# Análisis de estadísticas descriptivas
print("===================================")
print("=Estadísticas descriptivas del DataFrame combinado=")
print("===================================")
print(df.describe())

# Análisis de distribución de calificaciones
print("===================================")
print("= Distribución de calificaciones combinadas=")
print("= Para el primer grado G1 ==================")
print("============================================")
import matplotlib.pyplot as plt
import seaborn as sns
plt.figure(figsize=(12, 6))
sns.histplot(df['G1'], bins=20, kde=True)
plt.title('Distribución de Calificaciones Combinadas G1 ')
plt.xlabel('Calificaciones')
plt.ylabel('Frecuencia')
plt.show()

# Análisis de distribución de calificaciones
print("===================================")
print("= Distribución de calificaciones combinadas=")
print("= Para el segundo grado G2 ==================")
print("============================================")
import matplotlib.pyplot as plt
import seaborn as sns
plt.figure(figsize=(12, 6))
sns.histplot(df['G2'], bins=20, kde=True)
plt.title('Distribución de Calificaciones Combinadas G2 ')
plt.xlabel('Calificaciones')
plt.ylabel('Frecuencia')
plt.show()

# Análisis de distribución de calificaciones
print("===================================")
print("= Distribución de calificaciones combinadas=")
print("= Para el segundo grado G3 ==================")
print("============================================")
import matplotlib.pyplot as plt
import seaborn as sns
plt.figure(figsize=(12, 6))
sns.histplot(df['G3'], bins=20, kde=True)
plt.title('Distribución de Calificaciones Combinadas G3 ')
plt.xlabel('Calificaciones')
plt.ylabel('Frecuencia')
plt.show()



# Análisis de distribución de calificaciones
print("===================================")
print("= Distribución de calificaciones combinadas=")
print("= Para el segundo grado GP ==================")
print("============================================")
import matplotlib.pyplot as plt
import seaborn as sns
plt.figure(figsize=(12, 6))
sns.histplot(df['GP'], bins=20, kde=True)
plt.title('Distribución de Calificaciones Combinadas GP ')
plt.xlabel('Calificaciones')
plt.ylabel('Frecuencia')
plt.show()



# Análisis de distribución de calificaciones
print("===================================")
print("= Distribución de calificaciones ajustadas=")
print("= Para el segundo grado AdjG1==============")
print("===========================================")
import matplotlib.pyplot as plt
import seaborn as sns
plt.figure(figsize=(12, 6))
sns.histplot(df['AdjG1'], bins=5, kde=True)
plt.title('Distribución de Calificaciones Ajustadas AdjG1 ')
plt.xlabel('Calificaciones')
plt.ylabel('Frecuencia')
plt.show()

# Análisis de distribución de calificaciones
print("===================================")
print("= Distribución de calificaciones ajustadas=")
print("= Para el segundo grado AdjG2==============")
print("===========================================")
import matplotlib.pyplot as plt
import seaborn as sns
plt.figure(figsize=(12, 6))
sns.histplot(df['AdjG2'], bins=5, kde=True)
plt.title('Distribución de Calificaciones Ajustadas AdjG2')
plt.xlabel('Calificaciones')
plt.ylabel('Frecuencia')
plt.show()

# Análisis de distribución de calificaciones
print("===================================")
print("= Distribución de calificaciones ajustadas=")
print("= Para el segundo grado AdjG3==============")
print("===========================================")
import matplotlib.pyplot as plt
import seaborn as sns
plt.figure(figsize=(12, 6))
sns.histplot(df['AdjG3'], bins=5, kde=True)
plt.title('Distribución de Calificaciones Ajustadas AdjG3')
plt.xlabel('Calificaciones')
plt.ylabel('Frecuencia')
plt.show()



import matplotlib.pyplot as plt
import seaborn as sns

# Filtrar los datos para bajas ausencias (e.g., ausencias menores o iguales a 10, se puede ajustar el umbral)
df_low_absences = df[df['absences'] <= 10]

# Crear una gráfico conjunto para visualizar la relación entre AdjG1 y las ausencias
sns.jointplot(x='absences', y='G1', data=df_low_absences, kind='scatter', alpha=0.5)
# Usar G1 para hacer un gr´fico de dispersión usando los valores originales.

plt.suptitle('Relación entre G1 y las ausencias (bjasa ausencias)', y=1.02)
plt.show()

# Alternativamente, se puede usar un gráfico de enjambre o un gráfico de parada
# para ver la distribución de AdjG1 vs bajas ausencias.
plt.figure(figsize=(10, 6))
sns.swarmplot(x='AdjG1', y='absences', data=df_low_absences, order=['V', 'IV', 'III', 'II', 'I'])
plt.title('Distribución de las auencias contra la calificación ajustada G1 (Bajas ausencias)')
plt.xlabel('Calificación G1 ajustada')
plt.ylabel('Ausencias')
plt.show()

# Agrupar por AdjG1 y calcular la suma de ausencias
ausadjg1 = df.groupby('AdjG1')['absences'].sum()

# Mostrar el resultado
print("Acumulated absences by AdjG1:")
print(ausadjg1)

import matplotlib.pyplot as plt
import seaborn as sns

# Assuming ausadjg1 is already calculated and is a pandas Series
# If not, you would need to calculate it first:
# ausadjg1 = df.groupby('AdjG1', observed=False)['absences'].sum()

# Create a bar plot to visualize accumulated absences by AdjG1
plt.figure(figsize=(10, 6))
ausadjg1.plot(kind='bar')
plt.title('Accumulated Absences by Adjusted G1 Grade')
plt.xlabel('Adjusted G1 Grade')
plt.ylabel('Accumulated Absences')
plt.xticks(rotation=0) # Keep labels horizontal for better readability
plt.show()

# Agrupar Dalc por AdjG1 y calcular la suma de
daladjg1 = df.groupby('AdjG1')['Dalc'].sum()
waladjg1 = df.groupby('AdjG1')['Walc'].sum()
mjoadjg1 = df.groupby('AdjG1')['Mjob'].sum()

# Mostrar el resultado
print("Acumulated Dalc by AdjG1:")
print(daladjg1)
print("Acumulated Walc by AdjG1:")
print(waladjg1)
print("Acumulated Mjob by AdjG1:")
print(mjoadjg1)

import matplotlib.pyplot as plt
import seaborn as sns

# Assuming ausadjg1 is already calculated and is a pandas Series
# If not, you would need to calculate it first:
# ausadjg1 = df.groupby('AdjG1', observed=False)['absences'].sum()

# Create a bar plot to visualize accumulated absences by AdjG1
plt.figure(figsize=(10, 6))
daladjg1.plot(kind='bar')
plt.title('Accumulated Drink at job by Adjusted G1 Grade')
plt.xlabel('Adjusted G1 Grade')
plt.ylabel('Accumulated drink at job ')
plt.xticks(rotation=0) # Keep labels horizontal for better readability
plt.show()

import matplotlib.pyplot as plt
import seaborn as sns

# Assuming ausadjg1 is already calculated and is a pandas Series
# If not, you would need to calculate it first:
# ausadjg1 = df.groupby('AdjG1', observed=False)['absences'].sum()

# Create a bar plot to visualize accumulated absences by AdjG1
plt.figure(figsize=(10, 6))
waladjg1.plot(kind='bar')
plt.title('Accumulated Drink at week ends by Adjusted G1 Grade')
plt.xlabel('Adjusted G1 Grade')
plt.ylabel('Accumulated Drink at weekends ')
plt.xticks(rotation=0) # Keep labels horizontal for better readability
plt.show()

# Calculate the count of each mother's job for each AdjG1 category
mjob_adjg1_counts = df.groupby('AdjG1', observed=False)['Mjob'].value_counts().unstack(fill_value=0)

# Display the results
print("Distribution of Mothers' Jobs by Adjusted G1 Grade:")
print(mjob_adjg1_counts)

# You can also visualize this using a stacked bar chart
mjob_adjg1_counts.plot(kind='bar', stacked=True, figsize=(10, 6))
plt.title('Distribution of Mothers\' Jobs by Adjusted G1 Grade')
plt.xlabel('Adjusted G1 Grade')
plt.ylabel('Number of Students')
plt.xticks(rotation=0)
plt.legend(title='Mother\'s Job')
plt.show()

from sklearn.model_selection import train_test_split
from sklearn.linear_model import LinearRegression
from sklearn.metrics import mean_squared_error, r2_score
import pandas as pd

# Select features (independent variables) and target (dependent variable)
features = ['G1', 'Dalc', 'Walc', 'absences'] # Corrected features list to include 'AdjG1'
target = 'G2'

X = df[features].copy() # Create a copy to avoid SettingWithCopyWarning
y = df[target]

# Perform one-hot encoding on the 'AdjG1' column
X = pd.get_dummies(X, columns=['G1'], drop_first=True)

# Split data into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Initialize and train the Linear Regression model
model = LinearRegression()
model.fit(X_train, y_train)

# Make predictions on the test set
y_pred = model.predict(X_test)

# Evaluate the model
mse = mean_squared_error(y_test, y_pred)
rmse = mean_squared_error(y_test, y_pred) # Calculate RMSE
r2 = r2_score(y_test, y_pred)

print(f'Mean Squared Error (MSE): {mse:.2f}')
print(f'Root Mean Squared Error (RMSE): {rmse:.2f}')
print(f'R-squared (R2): {r2:.2f}')

# Display the model coefficients and intercept
print('\nModel Coefficients:')
# The features list needs to be updated after one-hot encoding
encoded_features = X_train.columns
for feature, coef in zip(encoded_features, model.coef_):
    print(f'{feature}: {coef:.2f}')
print(f'Intercept: {model.intercept_:.2f}')

from sklearn.model_selection import train_test_split
from sklearn.linear_model import LinearRegression
from sklearn.metrics import mean_squared_error, r2_score
import pandas as pd

# Select features (independent variables) and target (dependent variable)
features = ['G2', 'Dalc', 'Walc', 'absences'] # Corrected features list to include 'AdjG2'
target = 'G3'

X = df[features].copy() # Create a copy to avoid SettingWithCopyWarning
y = df[target]

# Perform one-hot encoding on the 'AdjG1' column
X = pd.get_dummies(X, columns=['G2'], drop_first=True)

# Split data into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Initialize and train the Linear Regression model
model = LinearRegression()
model.fit(X_train, y_train)

# Make predictions on the test set
y_pred = model.predict(X_test)

# Evaluate the model
mse = mean_squared_error(y_test, y_pred)
rmse = mean_squared_error(y_test, y_pred) # Calculate RMSE
r2 = r2_score(y_test, y_pred)

print(f'Mean Squared Error (MSE): {mse:.2f}')
print(f'Root Mean Squared Error (RMSE): {rmse:.2f}')
print(f'R-squared (R2): {r2:.2f}')

# Display the model coefficients and intercept
print('\nModel Coefficients:')
# The features list needs to be updated after one-hot encoding
encoded_features = X_train.columns
for feature, coef in zip(encoded_features, model.coef_):
    print(f'{feature}: {coef:.2f}')
print(f'Intercept: {model.intercept_:.2f}')